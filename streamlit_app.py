# streamlit_app_ce_batch_persistent.py
import io, os, tempfile, shutil
from dataclasses import dataclass
from typing import List, Dict
import pandas as pd
import streamlit as st
from openpyxl import load_workbook

st.set_page_config(page_title="í•™íšŒë¹„ ì¼ê´„ì ì¡°íšŒ", layout="wide")
st.title("í•™íšŒë¹„ ë‚©ë¶€ì ì¼ê´„ ì¡°íšŒ")

# -------- Persistent upload cache (disk) --------
UPLOAD_DIR = os.path.join(tempfile.gettempdir(), "dues_cache")
os.makedirs(UPLOAD_DIR, exist_ok=True)

def list_cached_files() -> Dict[str, str]:
    files = {}
    for fn in os.listdir(UPLOAD_DIR):
        path = os.path.join(UPLOAD_DIR, fn)
        if os.path.isfile(path) and fn.lower().endswith(('.xlsx', '.xls')):
            files[fn] = path
    return files

def cache_uploaded_file(uploaded_file) -> str:
    dst = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(dst, "wb") as f:
        f.write(uploaded_file.read())
    return dst

def clear_cache():
    if os.path.isdir(UPLOAD_DIR):
        shutil.rmtree(UPLOAD_DIR, ignore_errors=True)
    os.makedirs(UPLOAD_DIR, exist_ok=True)

# -------- Core logic --------
@dataclass
class Hit:
    grade: str
    class_name: str
    row: int
    student_id: str
    name: str
    status_cell: str
    verdict: str  # 'ë‚©ë¶€' or 'ë¯¸ë‚©'

def _norm(s):
    if s is None:
        return ""
    return str(s).strip()

def scan_workbook_path(path: str, filename: str, target_id: str,
                       start_row: int = 5, id_col: str = "C", name_col: str = "D", status_col: str = "E") -> List[Hit]:
    wb = load_workbook(path, data_only=True)
    tid = _norm(target_id).replace(" ", "")
    results: List[Hit] = []
    grade = os.path.splitext(filename)[0]  # '1í•™ë…„.xlsx' -> '1í•™ë…„'
    for ws in wb.worksheets:
        class_name = ws.title  # A/B/C...
        r = start_row
        while True:
            id_cell = ws[f"{id_col}{r}"].value
            sid = _norm(id_cell)
            if sid == "":
                break  # stop scanning this sheet at first blank in C
            if sid.replace(" ", "") == tid:
                name_val = ws[f"{name_col}{r}"].value
                name_text = _norm(name_val)
                status_val = ws[f"{status_col}{r}"].value
                status_text = _norm(status_val)
                verdict = "ë¯¸ë‚©" if status_text == "ë¯¸ë‚©" else "ë‚©ë¶€"
                results.append(Hit(grade, class_name, r, sid, name_text, status_text, verdict))
            r += 1
    return results

def batch_check_from_cache(student_ids, start_row=5) -> pd.DataFrame:
    out_rows = []
    cached = list_cached_files()  # {filename: path}
    for sid in student_ids:
        sid = _norm(sid)
        if not sid:
            continue
        found = False
        for fname, fpath in cached.items():
            hits = scan_workbook_path(fpath, fname, sid, start_row=start_row)
            if hits:
                found = True
                for h in hits:
                    out_rows.append({
                        "í•™ë²ˆ": h.student_id,
                        "ì´ë¦„": h.name,
                        "ìƒíƒœ": h.verdict,
                        "ì›ë³¸(Eì—´)": h.status_cell,
                        "í•™ë…„(íŒŒì¼ëª…)": h.grade,
                        "ë°˜(ì‹œíŠ¸ëª…)": h.class_name,
                        "í–‰": h.row
                    })
        if not found:
            out_rows.append({
                "í•™ë²ˆ": sid,
                "ì´ë¦„": "",
                "ìƒíƒœ": "ëª…ë‹¨ì— ì—†ìŒ",
                "ì›ë³¸(Eì—´)": "",
                "í•™ë…„(íŒŒì¼ëª…)": "",
                "ë°˜(ì‹œíŠ¸ëª…)": "",
                "í–‰": ""
            })
    return pd.DataFrame(out_rows, columns=["í•™ë²ˆ","ì´ë¦„","ìƒíƒœ","ì›ë³¸(Eì—´)","í•™ë…„(íŒŒì¼ëª…)","ë°˜(ì‹œíŠ¸ëª…)","í–‰"])

# -------- UI --------
with st.sidebar:
    st.header("ì„¤ì •")
    start_row = st.number_input("ì‹œì‘ í–‰", min_value=1, value=5, step=1)
    st.caption("ê° ì‹œíŠ¸ì—ì„œ Cì—´ì„ ì´ í–‰ë¶€í„° ë‚´ë ¤ê°€ë©° ì¡°íšŒ. Cì—´ì—ì„œ ë¹ˆ ì¹¸ì„ ë§Œë‚˜ë©´ ê·¸ ì‹œíŠ¸ì—ì„œ ì¤‘ë‹¨.")
    st.header("ìºì‹œ ê´€ë¦¬")
    if st.button("ğŸ§¹ ìºì‹œ ë¹„ìš°ê¸°(ì—…ë¡œë“œ íŒŒì¼ ì‚­ì œ)"):
        clear_cache()
        st.success("ìºì‹œë¥¼ ë¹„ì› ìŠµë‹ˆë‹¤. (ì—…ë¡œë“œ íŒŒì¼ ì‚­ì œ)")

st.subheader("1) í•™ë…„ë³„ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥, ì—…ë¡œë“œ í›„ ìœ ì§€)")
grade_files = st.file_uploader("1í•™ë…„.xlsx, 2í•™ë…„.xlsx â€¦ ì—…ë¡œë“œ", type=["xlsx"], accept_multiple_files=True)
if grade_files:
    saved = []
    for uf in grade_files:
        path = cache_uploaded_file(uf)
        saved.append(os.path.basename(path))
    if saved:
        st.success(f"ì—…ë¡œë“œ ë° ìºì‹œ ì €ì¥ ì™„ë£Œ: {', '.join(saved)}")

cached = list_cached_files()
if cached:
    st.info(f"í˜„ì¬ ìºì‹œëœ íŒŒì¼ ({len(cached)}): {', '.join(cached.keys())}")
else:
    st.warning("ìºì‹œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

st.subheader("2) í•™ë²ˆ ëª©ë¡ ì—…ë¡œë“œ ë˜ëŠ” ì…ë ¥")
uploaded_ids = st.file_uploader("í•™ë²ˆ CSV/XLSX íŒŒì¼ (ì²« ì—´ì´ í•™ë²ˆ)", type=["csv", "xlsx"])
manual_ids = st.text_area("ë˜ëŠ” ì§ì ‘ ì…ë ¥ (ì‰¼í‘œ/ì¤„ë°”ê¿ˆ êµ¬ë¶„)", placeholder="20230001, 20230002\n20230003")

student_ids = []
if uploaded_ids:
    try:
        if uploaded_ids.name.endswith(".csv"):
            try:
                df = pd.read_csv(uploaded_ids, dtype=str)
            except Exception:
                df = pd.read_csv(uploaded_ids, dtype=str, encoding="cp949")
        else:
            df = pd.read_excel(uploaded_ids, dtype=str)
        student_ids.extend(df.iloc[:, 0].dropna().astype(str).tolist())
    except Exception as e:
        st.error(f"í•™ë²ˆ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")

if manual_ids.strip():
    for part in manual_ids.splitlines():
        for x in part.split(","):
            if x.strip():
                student_ids.append(x.strip())

seen = set()
ids_unique = []
for x in student_ids:
    if x not in seen:
        ids_unique.append(x)
        seen.add(x)

if st.button("ì¼ê´„ ì¡°íšŒ"):
    if not cached:
        st.warning("ë¨¼ì € ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ì—…ë¡œë“œ í›„ ìºì‹œì— ì €ì¥ë©ë‹ˆë‹¤)")
    elif not ids_unique:
        st.warning("í•™ë²ˆì„ ì…ë ¥í•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì¡°íšŒ ì¤‘â€¦"):
            df_out = batch_check_from_cache(ids_unique, start_row=start_row)
        st.success(f"{len(ids_unique)}ê±´ ì¡°íšŒ ì™„ë£Œ!")
        st.dataframe(df_out, use_container_width=True)
        csv = df_out.to_csv(index=False).encode("utf-8-sig")
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="í•™íšŒë¹„_ì¼ê´„ì¡°íšŒ.csv", mime="text/csv")

st.caption("â€» ì´ ì•±ì€ ì—…ë¡œë“œí•œ ì—‘ì…€ íŒŒì¼ì„ ì„œë²„ì˜ ì„ì‹œ í´ë”ì— ë³´ê´€í•´ ì„¸ì…˜ì´ ëŠê²¨ë„ ìœ ì§€í•©ë‹ˆë‹¤. ë‹¨, í´ë¼ìš°ë“œ ì»¨í…Œì´ë„ˆê°€ ì¬ì‹œì‘ë˜ë©´ ì‚­ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
